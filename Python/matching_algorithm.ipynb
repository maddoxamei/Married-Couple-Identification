{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot import name 'linear_sum_assignment' from 'scipy.sparse.csgraph' (/home/mmaddox/.local/lib/python3.8/site-packages/scipy/sparse/csgraph/__init__.py)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# Matching\n",
    "try:\n",
    "    from scipy.sparse.csgraph import linear_sum_assignment\n",
    "except (Exception) as e:\n",
    "    print(e)\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matched Pairs Problem\n",
    "\n",
    "Stable marriage problem\n",
    "\n",
    "Minimum Weight Euclidean Matching (MWEM) \n",
    "Pefect matching between vectors in one group with another"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted bipartite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative to itertool's permutation function to create $\\frac{n!}{k!(n-k)!}$ matches where k = 2. These pairings eliminate duplicate pairings (i.e. considers 1,2 the same as 2,1). This method was inefficient. DON'T USE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cartesian_product( x, y ):\n",
    "    # Faster on smaller datasets (100, 70) but slower on larger datasets (500, 700)\n",
    "    return np.hstack([ np.repeat(x, y.shape[0], axis=0),\n",
    "               np.tile(y, (x.shape[0],1))] ).reshape(-1, 2, x.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Developed a custom method as the libraries in existance are limited to provide only one matching solution even if there are multiple solutions of equal likelihood. However, this method is not scalable (algorithmically and memory inefficient) and crashes my computer on medium-sized datasets (e.g. two matrices of shape (500, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product, permutations\n",
    "\n",
    "def match_pairs_custom(matrix_a, matrix_b):\n",
    "    \"\"\"\n",
    "    return: list of row indices\n",
    "    type: tuple(np.array, range)\n",
    "    \"\"\"\n",
    "    #pairs = np.array(list(product(random_m, random_f))) # as opposed to custom cartesian_product\n",
    "    dist = cdist(matrix_a, matrix_b, 'euclidean')\n",
    "    if dist.shape[0] != dist.shape[1]:\n",
    "        return None\n",
    "    n = dist.shape[0]\n",
    "    combinations = np.array(list(permutations(range(n))))\n",
    "    summation = np.choose(combinations, dist).sum(axis = 1) # Increment through columns and grab rows which corerspond to array\n",
    "    return combinations[np.where(summation == summation.min())] # respective column indices are all range(n)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for combination in match_pairs_custom(random_m[:3], random_f[:3]):\n",
    "    print( np.stack([combination, range(random_m[:3].shape[0])], axis = -1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If using **euclidean distance** ($\\sqrt{(a_1-b_1)^2+(a_2-b_2)^2\\dots+(a_n-b_n)^2}$), increasing distance values indicates decreasing similarity. \n",
    "\n",
    "If using **cosine distance** ($\\frac{a^Tb}{|a||b|}$), increasing distance values indicaties increasing similarity. \n",
    "\n",
    "A quick side-by-side speed comparison (see below) showed that using cosine distance with maximization had the best scalability.\n",
    "\n",
    "Scipy [linear_sum_assignment](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.linear_sum_assignment.html) function is the best minimization algorithm for dense networks. Scipy [maximum_bipartite_matching](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csgraph.maximum_bipartite_matching.html) function uses [Hopcroft–Karp algorithm](https://epubs.siam.org/doi/10.1137/0202019) for maximization, however it does NOT allow for weights along edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_pairs( matrix_a, matrix_b ):\n",
    "    \"\"\"\n",
    "    Determine the most optimal unique pairings between observations in matrix a with matrix b.\n",
    "    \n",
    "    @param: matrix_a:\n",
    "    @type: np.array\n",
    "    @param: matrix_b\n",
    "    @type: np.array\n",
    "    @return: (row indices simply increment )\n",
    "    @type: tuple(np.array, np.array)\n",
    "    \"\"\"\n",
    "    dist = cdist(matrix_a, matrix_b, 'euclidean')\n",
    "    return linear_sum_assignment(dist)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "import time\n",
    "\n",
    "random_m = np.random.rand(5000,100)\n",
    "random_f = np.random.rand(5000,100)\n",
    "\n",
    "times = np.array([])\n",
    "\n",
    "start = time.time()\n",
    "dist_min = cdist(random_m, random_f, 'euclidean')\n",
    "times = np.append( times, time.time() - start )\n",
    "\n",
    "start = time.time()\n",
    "dist_max = cdist(random_m, random_f, 'cosine')\n",
    "times = np.append( times, time.time() - start )\n",
    "\n",
    "start = time.time()\n",
    "linear_sum_assignment(dist_min)\n",
    "times = np.append( times, time.time() - start )\n",
    "\n",
    "start = time.time()\n",
    "linear_sum_assignment(dist_max, maximize = True)\n",
    "times = np.append( times, time.time() - start )\n",
    "\n",
    "start = time.time()\n",
    "linear_sum_assignment(cdist(random_m, random_f, 'euclidean'))\n",
    "times = np.append( times, time.time() - start )\n",
    "\n",
    "start = time.time()\n",
    "linear_sum_assignment(cdist(random_m, random_f, 'cosine'), maximize = True)\n",
    "times = np.append( times, time.time() - start )\n",
    "\n",
    "pd.DataFrame(times.reshape(3,2), index = [\"Distance Calculation\", \"Algorithm\", \"All\"], columns = [\"Minimize\", \"Maximize\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Hopcroft-Karp Algorithm](https://en.m.wikipedia.org/wiki/Hopcroft–Karp_algorithm)\n",
    "\n",
    "$min(\\sum_{i,j}d_{ij}x_{ij})\\Longrightarrow O(E{\\sqrt V})\\approx O(V^\\frac{3}{2})$ \n",
    "\n",
    "where $d_{ij}=distance~btw~V_i~and~V_j,$\n",
    "\n",
    "$x_{ij}=\\left\\{\\begin{matrix}1, & edge~belongs~to~matching \\\\ 0, & otherwise \\end{matrix}\\right.$\n",
    "\n",
    "**Constraints**\n",
    "\n",
    "1) Person $j$ paired with only one person from the other group: $\\sum_jx_{ij}=1~for~1\\le i\\le n$\n",
    "\n",
    "2) Person $i$ paired with only one person from the other group: $\\sum_ix_{ij}=1~for~1\\le j\\le n$\n",
    "\n",
    "3) Pairing between person $i$ and $j$ also means a pairing between $j$ and $i$: $x_{ij}\\ge0 for 1\\le i,j\\le n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pulp import LpVariable, LpProblem, LpMinimize, value, lpSum, LpBinary, LpStatus\n",
    "\n",
    "def match_pairs_custom(matrix_a, matrix_b):\n",
    "    dist = cdist(matrix_a, matrix_b, 'euclidean') # (matrix_a.shape[0], matrix_b.shape[0])\n",
    "    prob = LpProblem(\"Matching\", LpMinimize)\n",
    "    \n",
    "    variable_names = [str(i)+str(j) for i in range(matrix_a.shape[0]) for j in range(matrix_b.shape[0])]\n",
    "    variable_names.sort()\n",
    "    \n",
    "    relations = LpVariable.matrix(\"X\", variable_names, cat = \"Binary\")\n",
    "    allocation = np.array(relations).reshape(matrix_a.shape[0],matrix_b.shape[0])\n",
    "    \n",
    "    prob += lpSum(allocation*dist)\n",
    "    \n",
    "    for i in range(matrix_a.shape[0]):\n",
    "        prob += lpSum([allocation[i,j] for j in range(matrix_b.shape[0])]) == 1\n",
    "        prob += lpSum([allocation[j,i] for j in range(matrix_b.shape[0])]) == 1\n",
    "        prob += lpSum(allocation[i,j] + allocation[j,i] for j in range(matrix_b.shape[0])) >= 0\n",
    "        \n",
    "    prob.solve()\n",
    "    \n",
    "    print( 'Status:\\t', LpStatus[prob.status] )\n",
    "    print( 'Objective Value:\\t', prob.objective.value() )\n",
    "    \n",
    "    prob.writeLP(\"matching_prob.lp\")\n",
    "    \n",
    "    return [(v.name, v.value()) for v in prob.variables()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[A Survey on Algorithms for Euclidean Matching](https://courses.cs.duke.edu/fall08/cps234/projects/sayan_proj.pdf)\n",
    "\n",
    "$O(n^\\frac{3}{2}log(n))$\n",
    "\n",
    "$max(\\sum_i\\alpha_i+\\sum_j\\beta_j)$ subject to $\\alpha_i+\\beta_j\\le d_{ij}$ for $1\\le i,j\\le n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/linear-programming-using-python-priyansh-22b5ee888fe0\n",
    "    \n",
    "https://scaron.info/blog/linear-programming-in-python-with-pulp.html\n",
    "        \n",
    "https://towardsdatascience.com/how-to-match-two-people-with-python-7583b51ff3f9\n",
    "            \n",
    "https://medium.com/opex-analytics/optimization-modeling-in-python-pulp-gurobi-and-cplex-83a62129807a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pulp import LpVariable, LpProblem, LpMaximize, value, lpSum, LpStatus\n",
    "\n",
    "def match_pairs(matrix_a, matrix_b):\n",
    "    dist = cdist(matrix_a, matrix_b, 'euclidean') # (matrix_a.shape[0], matrix_b.shape[0])\n",
    "    prob = LpProblem(\"Matching\", LpMaximize)\n",
    "    \n",
    "    alpha = LpVariable.matrix( \"alpha\", [str(i) for i in range(matrix_a.shape[0])] )\n",
    "    beta = LpVariable.matrix( \"beta\", [str(j) for j in range(matrix_b.shape[0])] )\n",
    "    \n",
    "    for i in range(matrix_a.shape[0]):\n",
    "        for j in range(matrix_b.shape[0]):\n",
    "            prob += alpha[i] + beta[j] <= dist[i,j]\n",
    "            \n",
    "    prob += lpSum(alpha) + lpSum(beta)\n",
    "    prob.solve()\n",
    "    \n",
    "    print( 'Status:\\t', LpStatus[prob.status] )\n",
    "    print( 'Objective Value:\\t', prob.objective.value() )\n",
    "    \n",
    "    prob.writeLP(\"matching_prob.lp\")\n",
    "\n",
    "    return np.isclose(np.array([a.value()+b.value() for a, b in product(alpha, beta)]).reshape(dist.shape), dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_m = np.random.rand(100,2)\n",
    "random_f = np.random.rand(100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the CBC MILP Solver \n",
      "Version: 2.10.3 \n",
      "Build Date: Dec 15 2019 \n",
      "\n",
      "command line - /home/mmaddox/.local/lib/python3.8/site-packages/pulp/apis/../solverdir/cbc/linux/64/cbc /tmp/2261c87e8889499796e01cbcb5e82082-pulp.mps max timeMode elapsed branch printingOptions all solution /tmp/2261c87e8889499796e01cbcb5e82082-pulp.sol (default strategy 1)\n",
      "At line 2 NAME          MODEL\n",
      "At line 3 ROWS\n",
      "At line 10005 COLUMNS\n",
      "At line 30206 RHS\n",
      "At line 40207 BOUNDS\n",
      "At line 40408 ENDATA\n",
      "Problem MODEL has 10000 rows, 200 columns and 20000 elements\n",
      "Coin0008I MODEL read with 0 errors\n",
      "Option for timeMode changed from cpu to elapsed\n",
      "Presolve 10000 (0) rows, 200 (0) columns and 20000 (0) elements\n",
      "Perturbing problem by 0.001% of 1 - largest nonzero change 0 ( 0%) - largest zero change 0\n",
      "0  Obj -0 Dual inf 1.99998 (200) w.o. free dual inf (0)\n",
      "0  Obj -0 Dual inf 1.99998 (200) w.o. free dual inf (0)\n",
      "275  Obj 10.351206 Dual inf 16.999999 (11)\n",
      "316  Obj 10.574242\n",
      "Optimal - objective value 10.574242\n",
      "Optimal objective 10.57424187 - 316 iterations time 0.052\n",
      "Option for printingOptions changed from normal to all\n",
      "Total time (CPU seconds):       0.06   (Wallclock seconds):       0.08\n",
      "\n",
      "Status:\t Optimal\n",
      "Objective Value:\t 10.574241876799997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_pairs(random_m, random_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neither of these package functions were loading correctly. Therefore did math by hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non bipartite"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
