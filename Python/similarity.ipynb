{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf72cfbb-db50-44d9-87ed-8cccc4a53068",
   "metadata": {},
   "outputs": [],
   "source": [
    "from global_variables import *\n",
    "from similarity import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1bed2f-74ea-4fec-b469-1fee36538cd3",
   "metadata": {},
   "source": [
    "# Load and Clean the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79e30564-9b5f-4861-ad85-8aa1fc831d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E    52268\n",
      "K    13372\n",
      "Name: customer_gender, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "%run ./preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff1166a-c58a-422a-be61-22d29f99feb2",
   "metadata": {},
   "source": [
    "# Split into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3128024-ce6d-4e95-9cda-2004f25fd79b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36587, 42), (5227, 42), (10454, 42))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset_male, valset_male, evalset_male = dataset_splits(df_male)\n",
    "trainset_male.shape, valset_male.shape, evalset_male.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3fdc999-e859-45f4-b187-c2a9e6f609a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9360, 42), (1337, 42), (2675, 42))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset_female, valset_female, evalset_female = dataset_splits(df_female)\n",
    "trainset_female.shape, valset_female.shape, evalset_female.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c790d06-a9da-4346-b02e-987fc274316d",
   "metadata": {},
   "source": [
    "# Self-Supervised Similarity Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de85b837-a809-4ad5-bc88-bab7709b36b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['customer_main_branch_x_coord', 'customer_main_branch_y_coord',\n",
       "       'customer_home_x_coord', 'customer_home_y_coord',\n",
       "       'customer_income_level', 'customer_age', 'akbank_banking_age',\n",
       "       '1)RISKSIZ', '2)GECIKME 1-15 GUN', '3)GECIKME 16-29 GUN',\n",
       "       '4)GECIKME 30-59 GUN', '5)GECIKME 60+ GUN', '6)TAKIP', 'BV_DoW_0',\n",
       "       'BV_DoW_1', 'BV_DoW_2', 'BV_DoW_3', 'BV_DoW_4', 'BV_DoW_5', 'BV_DoW_6',\n",
       "       'BV_very_early', 'BV_early', 'BV_later', 'BV_late',\n",
       "       'branch_mean_distance', 'payment_mean', 'payment_std',\n",
       "       'payment_monthly_freq', 'trans_average_amount_AKARYAKIT',\n",
       "       'trans_average_amount_GIDA', 'trans_average_amount_OTHER',\n",
       "       'trans_average_amount_RESTORAN', 'trans_average_amount_TEKSTÝL',\n",
       "       'trans_average_monthly_freq_AKARYAKIT',\n",
       "       'trans_average_monthly_freq_GIDA', 'trans_average_monthly_freq_OTHER',\n",
       "       'trans_average_monthly_freq_RESTORAN',\n",
       "       'trans_average_monthly_freq_TEKSTÝL', 'statement_amount_TL_mean',\n",
       "       'statement_amount_TL_std', 'customer_education_level',\n",
       "       'customer_job_status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_male.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69d386e-efed-46ad-b96b-cffa2a3d4680",
   "metadata": {},
   "source": [
    "**Domain knowledge leads us to believe certain features will be better predictors of partnership than others.** \n",
    "- branch xy\n",
    "- home xy\n",
    "- income\n",
    "- age\n",
    "- <font color='red'>bank age</font>\n",
    "- risk levels\n",
    "- <font color='red'>bank visit date/time</font>\n",
    "- bank span\n",
    "- <font color='red'>avg. spending in category</font>\n",
    "- <font color='red'>avg. frequency in category</font>\n",
    "- statement mean/std\n",
    "- customer education\n",
    "- <font color='red'>job status</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736efc40-6888-4698-9044-3d27bddf3755",
   "metadata": {},
   "source": [
    "**banking age:** Except for the rare cases when they signed up together, it's not indicitive of similarity (i.e. we assume that the majority of partnerships has one member being longer-established at a bank and convincing the other to join theirs)\n",
    "\n",
    "**bank visit date/time:**\n",
    "\n",
    "\n",
    "**Avg. spending/frequency:**\n",
    "\n",
    "\n",
    "**Job status:** In this day and age there are several combinations of married working dynamics that such column would be convoluted and not a generalizable metric, especially considering the categories provided - _Paid (Special), Self Employment, Paid (Public), Retired, Retired (Paid), Housewife, Unemployed, Retired (Self-Employed), Student, Working Abroad, Children, Undefined, Other_ -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fd956ff-09b7-4252-95f9-77e0ab72fcf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(36587, 19), (5227, 19), (10454, 19)], [(9360, 19), (1337, 19), (2675, 19)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removal_list = np.concatenate([['akbank_banking_age','customer_job_status'], df_male.filter(regex = 'trans|BV').columns], axis = 0)\n",
    "\n",
    "male_targets = [dataset.drop(removal_list, axis = 1) for dataset in [trainset_male, valset_male, evalset_male]]\n",
    "female_targets = [dataset.drop(removal_list, axis = 1) for dataset in [trainset_female, valset_female, evalset_female]]\n",
    "\n",
    "[dataset.shape for dataset in male_targets], [dataset.shape for dataset in female_targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a9ec756-0ed6-42ad-87c2-e0e167895053",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_autopredictor():\n",
    "    autoencoder_male = Autoencoder(10, output_dimension = 19, hidden_layers = 2, activation = tf.nn.relu)\n",
    "    autoencoder_male.compile(optimizer='adam', loss=tf.losses.MeanSquaredError())\n",
    "    \n",
    "    autoencoder_female = Autoencoder(10, output_dimension = 19, hidden_layers = 2, log_progression = False, activation = tf.nn.relu)\n",
    "    autoencoder_female.compile(optimizer='adam', loss=tf.losses.MeanSquaredError())\n",
    "    \n",
    "    autoencoder = Autoencoder(10, output_dimension = 19, hidden_layers = 2, log_progression = False, activation = tf.nn.relu)\n",
    "    autoencoder.compile(optimizer='adam', loss=tf.losses.MeanSquaredError())\n",
    "    \n",
    "    history_male = autoencoder_male.fit(trainset_male, male_targets[0],\n",
    "                                       validation_data=(valset_male, male_targets[1]),\n",
    "                                       epochs=50,\n",
    "                                       shuffle=True,\n",
    "                                       callbacks = [early_stopping],\n",
    "                                       verbose = 0)\n",
    "    \n",
    "    save_model(autoencoder_male, \"encoding_male\")\n",
    "    save_history(history_male, \"history_male\")\n",
    "    \n",
    "    history_female = autoencoder_female.fit(trainset_female, female_targets[0],\n",
    "                               validation_data=(valset_female, female_targets[1]),\n",
    "                               epochs=50,\n",
    "                               shuffle=True,\n",
    "                               callbacks = [early_stopping],\n",
    "                               verbose = 0)\n",
    "    \n",
    "    save_model(autoencoder_female, \"encoding_female\")\n",
    "    save_history(history_female, \"history_female\")\n",
    "    \n",
    "    history = autoencoder.fit(pd.concat([trainset_male, trainset_female], axis = 0), pd.concat([male_targets[0], female_targets[0]], axis = 0),\n",
    "                               validation_data=(pd.concat([valset_male, valset_female], axis = 0), pd.concat([male_targets[1], female_targets[1]], axis = 0)),\n",
    "                               epochs=50,\n",
    "                               shuffle=True,\n",
    "                               callbacks = [early_stopping],\n",
    "                               verbose = 0)\n",
    "    \n",
    "    save_model(autoencoder, \"encoding\")\n",
    "    save_history(history, \"history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d164f44c-7554-4329-98f4-b92b0d5d9059",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-09 22:01:55.512195: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-05-09 22:01:55.512230: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-05-09 22:01:55.512772: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-09 22:03:39.599197: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_2_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/encoding_male/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/encoding_male/assets\n",
      "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_2_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/encoding_female/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/encoding_female/assets\n",
      "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_2_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/encoding/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/encoding/assets\n"
     ]
    }
   ],
   "source": [
    "train_autopredictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f60782c-4a7d-427d-b3d8-4ee074abcc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder (Encoder)           multiple                  1388      \n",
      "                                                                 \n",
      " decoder (Decoder)           multiple                  439       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,827\n",
      "Trainable params: 1,827\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_1 (Encoder)         multiple                  1388      \n",
      "                                                                 \n",
      " decoder (Decoder)           multiple                  439       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,827\n",
      "Trainable params: 1,827\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_2 (Encoder)         multiple                  1388      \n",
      "                                                                 \n",
      " decoder (Decoder)           multiple                  439       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,827\n",
      "Trainable params: 1,827\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder_male = tf.keras.models.load_model(os.path.join(model_path, \"encoding_male\"), compile=True)\n",
    "autoencoder_female = tf.keras.models.load_model(os.path.join(model_path, \"encoding_female\"), compile=True)\n",
    "autoencoder = tf.keras.models.load_model(os.path.join(model_path, \"encoding\"), compile=True)\n",
    "    \n",
    "autoencoder_male.summary()\n",
    "autoencoder_female.summary()\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd17af3e-19fa-4d65-8dc7-a07ef2b26254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Loss (Male):\n",
      "\t 1.6002641916275024\n",
      "Evaluation Loss (Female):\n",
      "\t 1.5510011911392212\n",
      "Evaluation Loss (Joint):\n",
      "\t 1.5910412073135376\n"
     ]
    }
   ],
   "source": [
    "print( \"Evaluation Loss (Male):\\n\\t\", autoencoder_male.evaluate(evalset_male, male_targets[2], verbose = 0))\n",
    "print( \"Evaluation Loss (Female):\\n\\t\", autoencoder_female.evaluate(evalset_female, female_targets[2], verbose = 0))\n",
    "print( \"Evaluation Loss (Joint):\\n\\t\", autoencoder.evaluate(pd.concat([evalset_male, evalset_female], axis = 0), pd.concat([male_targets[2], female_targets[2]], axis = 0), verbose = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9130a24b-209b-4718-99b6-51d7feef84ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_males = autoencoder_male.encoder(df_male.to_numpy()).numpy()\n",
    "encoded_females = autoencoder_female.encoder(df_female.to_numpy()).numpy()\n",
    "\n",
    "encoded_males = pd.DataFrame(encoded_males, index = df_male.index)\n",
    "encoded_males.to_csv(os.path.join(data_path,'encoded_males_sep.csv'))\n",
    "\n",
    "encoded_females = pd.DataFrame(encoded_females, index = df_female.index)\n",
    "encoded_females.to_csv(os.path.join(data_path,'encoded_females_sep.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d71016db-2c0b-4172-9ed5-860eb6c19d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_males = autoencoder.encoder(df_male.to_numpy()).numpy()\n",
    "encoded_females = autoencoder.encoder(df_female.to_numpy()).numpy()\n",
    "\n",
    "encoded_males = pd.DataFrame(encoded_males, index = df_male.index)\n",
    "encoded_males.to_csv(os.path.join(data_path,'encoded_males_joint.csv'))\n",
    "\n",
    "encoded_females = pd.DataFrame(encoded_females, index = df_female.index)\n",
    "encoded_females.to_csv(os.path.join(data_path,'encoded_females_joint.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31835142-a78e-40d8-bedd-428ce95bb566",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
